{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Squared Error\n",
    "\n",
    "* MSE ε R<sup>+</sup>\n",
    "* MSE = Average(Indicators - Indicator<sup>2</sup>)\n",
    "* ⇔ MSE = Bias(Indicator)<sup>2</sup> + Variance(Indicator)\n",
    "* As we can see, it can be defined as a mesure of the bias and variance of the Indicator\n",
    "* It evaluates the quadratic risk of the Indicator\n",
    "* Sensitive to outliers (large error values), thus usefull when we want our model to be quite stable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Mean Squared-Error\n",
    "\n",
    "* RMSE ε R<sup>+</sup>\n",
    "* RMSE = √(MSE) = √(Average(Indicators - Indicator<sup>2</sup>))\n",
    "* ⇔ RMSE = √(Bias(Indicator)<sup>2</sup> + Variance(Indicator))\n",
    "* As we can see, it can be defined as a mesure of the standard deviation of the Indicator\n",
    "* It evaluates the quadratic risk of the Indicator\n",
    "* Even more Sensitive to outliers (large error values), thus usefull when we want our model to avoid large errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Bias Error\n",
    "\n",
    "* MBE ε R\n",
    "* MBE = Average(Y<sub>label</sub> - Y<sub>predicted</sub>)\n",
    "* As we can see, it can be defined as a mesure of the bias of the error between labels and predictions\n",
    "* It indicates if the model surestimate (if MBE < 0)  or underestimate (if MBE > 0) the output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Systematic Error\n",
    "\n",
    "* SE or SD ε R<sup>+</sup>\n",
    "* SD = √(RMSE(error)<sup>2</sup> - MBE(error)<sup>2</sup>)\n",
    "* As we can see, it can be defined as a mesure of the MSE-Bias so it reduces the importance of larger errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error\n",
    "\n",
    "* MAE ε R<sup>+</sup>\n",
    "* MAE = Average(|Y<sub>label</sub> - Y<sub>predicted</sub>|)\n",
    "* As we can see, it can be defined as a mesure of the bias, not regarding to its orientation\n",
    "* MAE will not be sensible to outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Absolute Pourcentage Error\n",
    "\n",
    "* MAPE ε R<sup>+</sup>\n",
    "* MAPE = Average(|(Y<sub>label</sub> - Y<sub>predicted</sub>) / Y<sub>label</sub>|)\n",
    "* As we can see, it can be defined as a mesure of the bias, not regarding to its orientation \n",
    "* It has the advantage to show ratio errors rather than value errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R<sup>2</sup>\n",
    "\n",
    "* R<sup>2</sup> ε R, R<sup>2</sup> ε [-1, 1]\n",
    "* R<sup>2</sup> = Correlation(Y<sub>predicted</sub>, Y<sub>label</sub>)\n",
    "* ⇔ R<sup>2</sup> = Sum((Y<sub>predicted</sub> - Average(Y<sub>label</sub>))<sup>2</sup>/Sum((Y<sub>label</sub> - Average(Y<sub>label</sub>))<sup>2</sup>\n",
    "* As we can see, it can be defined as a mesure of the correlation of the error\n",
    "* It has the advantages to put every error on the same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
