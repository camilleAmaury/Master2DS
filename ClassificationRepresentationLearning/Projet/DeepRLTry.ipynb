{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Data Camp\n",
    "\n",
    "This project can be found at \"./datacamp.pdf\". The aim is to find a way to maximize the \"cells\" size eaten at specific location within a limited range of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "In this section, we will import, open data and manage to explore and maybe reorganize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Datascience libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "# basic python libraries\n",
    "import math\n",
    "import time\n",
    "from tqdm.notebook import tqdm as pb\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 16, 10\n",
    "\n",
    "# local imports\n",
    "from classes.Game import *\n",
    "from classes.Strategy import *\n",
    "from classes.Metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-11.03</td>\n",
       "      <td>-82.33</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-4.93</td>\n",
       "      <td>-98.05</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>81.52</td>\n",
       "      <td>2.41</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>36.82</td>\n",
       "      <td>-42.62</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-69.86</td>\n",
       "      <td>11.88</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2   3\n",
       "0  0 -11.03 -82.33  46\n",
       "1  1  -4.93 -98.05  96\n",
       "2  2  81.52   2.41  49\n",
       "3  3  36.82 -42.62  71\n",
       "4  4 -69.86  11.88  27"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parser de fichiers\n",
    "df = pd.read_csv(\"data.txt\",header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     8.00\n",
       "1   -56.27\n",
       "2    23.81\n",
       "3    65.00\n",
       "Name: 8, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[8,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Graph and store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dist_matrix(M):\n",
    "    dim = M.shape[0]\n",
    "    dist_M = np.zeros((dim,dim))\n",
    "    for i in pb(range(dim)):\n",
    "        for j in range(dim):\n",
    "            dist_M[i,j] = math.sqrt((M[i,1] - M[j,1])**2 + (M[i,2] - M[j,1])**2)\n",
    "    return dist_M\n",
    "\n",
    "def create_init_dist_array(M, pos):\n",
    "    dim = M.shape[0]\n",
    "    dist_arr = np.zeros((dim))\n",
    "    for i in pb(range(dim)):\n",
    "        dist_arr[i] = math.sqrt((pos[0] - M[i,1])**2 + (pos[1] - M[i,1])**2)\n",
    "    return dist_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d29baffd3a944419f464ab8f81b5214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances = create_dist_matrix(M)\n",
    "distances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca359ccc9924c4a956a45dde3a5cf99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_position = (0,0)\n",
    "init_distances = create_init_dist_array(M, init_position)\n",
    "init_distances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deep rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, max_size, input_shape, n_actions, discrete=False):\n",
    "        super(ReplayBuffer, self).__init__()\n",
    "        self.mem_size = max_size\n",
    "        self.discrete = discrete\n",
    "        self.state_memory = np.zeros((self.mem_size, input_shape))\n",
    "        self.new_state_memory = np.zeros((self.mem_size, input_shape))\n",
    "        dtype = np.int8 if self.discrete else np.float32\n",
    "        self.action_memory = np.zeros((self.mem_size, n_actions), dtype=dtype)\n",
    "        self.reward_memory = np.zeros(self.mem_size)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.mem_counter = 0\n",
    "        \n",
    "    def store_transition(self, state, action, reward, new_state, done):\n",
    "        index = self.mem_counter % self.mem_size\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = new_state\n",
    "        self.reward_memory[index] = reward\n",
    "        self.terminal_memory[index] = 1 - int(done)\n",
    "        \n",
    "        if self.discrete:\n",
    "            actions = np.zeros(self.action_memory.shape[1])\n",
    "            actions[action] = 1.0\n",
    "            self.action_memory[index] = actions\n",
    "        else:\n",
    "            self.action_memory[index] = action\n",
    "        self.mem_counter += 1\n",
    "        \n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_mem = min(self.mem_counter, self.mem_size)\n",
    "        batch = np.random.choice(max_mem, batch_size)\n",
    "        \n",
    "        states = self.state_memory[batch]\n",
    "        new_states = self.new_state_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        terminal = self.terminal_memory[batch]\n",
    "        \n",
    "        return states, actions, rewards, new_states, terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, alpha, gamma, n_actions, epsilon, batch_size, input_dims,\n",
    "                fn, epsilon_decrease=0.0001, epsilon_min=0.0001, mem_size=1000000,\n",
    "                fname=\"dqn_model\"):\n",
    "        super(Agent, self).__init__()\n",
    "        self.action_space = [i for i in range(n_actions)]\n",
    "        self.n_actions = n_actions\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_dec = epsilon_decrease\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.batch_size = batch_size\n",
    "        self.model_file = fname\n",
    "        \n",
    "        self.memory = ReplayBuffer(mem_size, input_dims, n_actions, \n",
    "                                   discrete=True)\n",
    "        self.q_eval = fn(alpha, n_actions, input_dims, 128, 128)\n",
    "    \n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.memory.store_transition(state, action, reward, new_state, done)\n",
    "    \n",
    "    def create_state(self, distances, rewards):\n",
    "        return rewards/np.power(distances,3)\n",
    "    \n",
    "    def choose_action(self, state, time):\n",
    "        rand = np.random.random()\n",
    "        if rand < self.epsilon:\n",
    "            action = np.random.choice(self.action_space)\n",
    "        else:\n",
    "            state_ = state[np.newaxis,:]\n",
    "            actions = self.q_eval.predict(state_)\n",
    "            action = np.argmax(actions)\n",
    "        return action\n",
    "    \n",
    "    def learn(self):\n",
    "        if self.memory.mem_counter < self.batch_size:\n",
    "            return\n",
    "        state, action, reward, new_state, done = self.memory.sample_buffer(self.batch_size)\n",
    "        \n",
    "        action_values = np.array(self.action_space, dtype=np.int8)\n",
    "        action_indices = np.dot(action, action_values)\n",
    "        \n",
    "        q_eval = self.q_eval.predict(state)\n",
    "        q_next = self.q_eval.predict(new_state)\n",
    "        \n",
    "        q_target = q_eval.copy()\n",
    "        \n",
    "        batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
    "        q_target[batch_index, action_indices] = reward + self.gamma*np.max(q_next, axis=1)*done\n",
    "        \n",
    "        \n",
    "        _ = self.q_eval.fit(state, q_target, verbose=0)\n",
    "        \n",
    "        \n",
    "    def decrease(self):\n",
    "        self.epsilon = self.epsilon-self.epsilon_dec if self.epsilon > self.epsilon_min else self.epsilon_min\n",
    "    def save_model(self):\n",
    "        self.q_eval.save(self.model_file)\n",
    "    def load_model(self):\n",
    "        self.q_eval = load_model(self.model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game(object):\n",
    "    \n",
    "    def __init__(self, time, distances, init_distances):\n",
    "        super(Game, self).__init__()\n",
    "        self._const_time = time\n",
    "        self.distances = distances\n",
    "        self.init_distances = init_distances\n",
    "    \n",
    "    # init a game and reset it\n",
    "    def init_game(self, M, init_coord):\n",
    "        self._Rewards = M[:,2]\n",
    "        self._Ids = M[:, 0].astype(int)\n",
    "        self.actual_position = -1\n",
    "        self.ids = []\n",
    "        self.rewards = []\n",
    "        self.time = 0.\n",
    "        return self.init_distances, self._Rewards\n",
    "\n",
    "    # step in a game\n",
    "    def step_env(self, action):\n",
    "        # check if there is a correct action or not\n",
    "        distance = self.distances[self.actual_position, action]\n",
    "        if self.time + distance >= self._const_time:\n",
    "            return self.distances[self.actual_position,:], self._Rewards, 1, True, \"End of Game\"\n",
    "        else:\n",
    "            # update rewards\n",
    "            if self._Rewards[action] == 0.:\n",
    "                previous_reward = -distance**3\n",
    "            else:\n",
    "                previous_reward = self._Rewards[action]/distance**3\n",
    "            self.rewards.append(self._Rewards[action])\n",
    "            self._Rewards[action] = 0.\n",
    "\n",
    "            # update distance\n",
    "            self.time += distance\n",
    "            \n",
    "            # move and keep track of action\n",
    "            self.actual_position = action\n",
    "            self.ids.append(self._Ids[action])\n",
    "\n",
    "            # step into the environnement\n",
    "            dist, rew, ids = self.find_n_nearest_neightbors(self.actual_position)\n",
    "            return self.distances[self.actual_position,:], self._Rewards, previous_reward, False, \"Step\"\n",
    "    \n",
    "    # string representation of the object\n",
    "    def __repr__(self):\n",
    "        return \"<Object : Game (DataCamp) <> time:{}>\".format(self._const_time)\n",
    "    def __str__(self):\n",
    "        return self.__repr__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(learning_rate, n_actions, input_dims, fc1_dims, fc2_dims):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(fc1_dims, input_shape=(input_dims,), activation='relu'))\n",
    "    model.add(Dense(fc2_dims, activation='relu'))\n",
    "    model.add(Dense(n_actions, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=\"adam\",loss=\"mse\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = df.values\n",
    "n = M.shape[0]\n",
    "env = Game(10000., distances, init_distances)\n",
    "agent = Agent(gamma=0.90, epsilon=1.0, alpha=0.001, input_dims=n, n_actions=n,\n",
    "             fn=build_network,mem_size=10_000, batch_size=2000)\n",
    "#agent.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251d1aac0ed847f588137cbb46410121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-978cbf8cba12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_distances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_rewards\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_const_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mtemp_distances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_rewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_env\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mobservation_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_distances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_rewards\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-56-151860a1e334>\u001b[0m in \u001b[0;36mchoose_action\u001b[1;34m(self, state, time)\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "_n_games = 100\n",
    "scores = []\n",
    "max_ = [0]\n",
    "for epoch in range(1):\n",
    "    agent.epsilon = 1.\n",
    "    agent.epsilon_decrease= 1./_n_games,\n",
    "    agent.epsilon_min= 1./_n_games\n",
    "    for i in pb(range(_n_games)):\n",
    "        done = False\n",
    "        temp_distances, temp_rewards = env.init_game(np.copy(M), init_position)\n",
    "        observation = agent.create_state(temp_distances, temp_rewards)\n",
    "        while not done:\n",
    "            action = agent.choose_action(observation, env._const_time - env.time)\n",
    "            temp_distances, temp_rewards, reward, done, info = env.step_env(action)\n",
    "            observation_ = agent.create_state(temp_distances, temp_rewards)\n",
    "            agent.remember(observation, action, reward, observation_, done)\n",
    "            observation = observation_\n",
    "        agent.learn()\n",
    "        agent.decrease()\n",
    "        if max_[0] < sum(env.rewards):\n",
    "            max_ = [sum(env.rewards), env.ids]\n",
    "        scores.append(sum(env.rewards))\n",
    "    agent.save_model() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save_model() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x27477affc08>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(np.arange(0, len(scores)),scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_result(M, ids):\n",
    "    M_temp = np.copy(M)\n",
    "    rewards = []\n",
    "    dist = 10000.\n",
    "    coordinate = (0.,0.)\n",
    "    for i in ids:\n",
    "        rewards.append(M_temp[i, 3])\n",
    "        M_temp[i, 3] = 0.\n",
    "        dist -= math.sqrt((coordinate[0] - M_temp[i, 1])**2 + (coordinate[1] - M_temp[i, 2])**2)\n",
    "        coordinate = (M_temp[i, 1],M_temp[i, 2])\n",
    "        \n",
    "    print(dist, sum(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.302929195682935 5452.0\n"
     ]
    }
   ],
   "source": [
    "check_result(M,max_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 87.23353942,  93.12      , 199.29623027, ..., 118.39940878,\n",
       "        66.9264447 , 107.24787364])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
